{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a74cb9a",
   "metadata": {},
   "source": [
    "# **Proyecto final de Ciencia de Datos II - Coder House**\n",
    "# ~ Modelo de predicci√≥n de precios de veh√≠culos ~\n",
    "Estudiante: **Gonzalo Leonel Gramajo**  \n",
    "Comisi√≥n: **75690**  \n",
    "Documento: **40441349**  \n",
    "A√±o: **2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20828f05",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 1. **INTRODUCCI√ìN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05b78a",
   "metadata": {},
   "source": [
    "Este notebook corresponde al trabajo final del curso \"CIENCIA DE DATOS II\" de Coder House.  \n",
    "Est√° basado en un dataset de ventas de autos rescatado desde Keegle. Este conjunto de datos incluye todas las publicaciones de veh√≠culos usados ‚Äã‚Äãdentro de los Estados Unidos en Craigslist.com.\n",
    "Es importante resaltar que se cuenta con 426 mil lineas y el archivo ocupa 1.45 GB de almacenamiento, por lo que un archivo de tal tama√±o no se peude subir a GitHub. Dado esto, el archivo .csv se puede encontrar disponible en Google Drive y Kaggle.\n",
    "\n",
    "### **Dataset**\n",
    "Used Cars Dataset - Vehicles listings from Craigslist.org.  \n",
    "Enlace web a Kaggle: https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data  \n",
    "Enlace web a Google Drive: https://drive.google.com/file/d/1uQ_YhqBimI46j5W-EgSwkjZvpFt87ejt/view?usp=sharing\n",
    "\n",
    "### **Objetivo general**\n",
    "*Lograr un modelo predictivo que logre inferir autom√°ticamente el precio de los veh√≠culos acorde a las caracteristicas m√°s relevantes de los mismos.*\n",
    "\n",
    "### **Objetivos espec√≠ficos**\n",
    "* *Encontrar las variables de correlaci√≥n principales con el precio del veh√≠culo.*\n",
    "* *Lograr un primer modelo predictivo y evaluar su rendimiento.*\n",
    "* *Generar un modelo predictivo optimizado con m√©tricas maximizadas.*\n",
    "\n",
    "### **Preguntas de inter√©s**\n",
    "\n",
    "1. ¬øLos autos con menos kilometraje (odometer) tienden a ser m√°s valorados?  \n",
    "1.1. ¬øCu√°l es la correlaci√≥n entre el kilometraje (odometer) y el precio del veh√≠culo?  \n",
    "1.2. ¬øExiste un umbral de kilometraje a partir del cual el valor del veh√≠culo cae significativamente?  \n",
    "  \n",
    "2. ¬øC√≥mo var√≠a el precio de los veh√≠culos seg√∫n su marca/fabricante?  \n",
    "2.1. ¬øQu√© marcas presentan mayor dispersi√≥n de precios en sus publicaciones?  \n",
    "2.2. ¬øExisten marcas cuyos veh√≠culos est√°n consistentemente sobrevalorados o subvalorados respecto a la media general?    \n",
    "  \n",
    "3. ¬øLos veh√≠culos con a√±o de fabricaci√≥n menor, se venden exponencialmente mas caros?  \n",
    "3.1. ¬øC√≥mo var√≠a el precio medio de los veh√≠culos seg√∫n el a√±o de fabricaci√≥n?  \n",
    "3.2. ¬øSe observa una depreciaci√≥n lineal o no lineal del precio con el paso de los a√±os?  \n",
    "   \n",
    "4. ¬øLos Fabricantes con m√°s publicaciones, son los que se acercan m√°s a la media del precio?   \n",
    "4.1. ¬øLos fabricantes con m√°s publicaciones son de marcas nacionales?   \n",
    "4.2. ¬øLos fabricantes nacionales tienen precios m√°s bajos que otras marcas?   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d8cbd",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 2. **CARGA Y VERIFICACI√ìN DE DATOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6bd38",
   "metadata": {},
   "source": [
    "### 2.1. **CARGA DE DATOS E IMPORTACIONES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3de20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herramientas principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# M√≥dulos de visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carga el archivo CSV en un DataFrame de pandas\n",
    "file_path = './vehicles.csv' # ruta al archivo CSV\n",
    "df = pd.read_csv(file_path) # leer el archivo CSV y conseguir un dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e4a44",
   "metadata": {},
   "source": [
    "Mostrar  las primeras 5 lineas del dataframe cargao para tener un pantallazo de que se trata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106bb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # mostrar los primeros 5 valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e727032",
   "metadata": {},
   "source": [
    "A simple vista y r√°pidamente se puede observar una gran cantidad de informaci√≥n que no es relevante para el objetivo, como ser las URLs. Tambi√©n se ve muchos NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1bf47",
   "metadata": {},
   "source": [
    "### 2.2. **REVISI√ìN GENERAL Y LIMPIEZA INICIAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(\"\\n Cantidad de valores nulos por columna: \\n\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdefd9",
   "metadata": {},
   "source": [
    "**Revisar si year tiene decimales**. En la \"info\" del dataframe, se puede ver que year es de tipo float. Esto es algo extra√±o ya que suelen ser valores enteros, por lo tanto, se debe averiguar por qu√© esto es as√≠. Puede ser que existan valores decimales o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03184387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para verificar si hay decimales en una columna\n",
    "def tiene_decimales(serie):\n",
    "    return (serie % 1 != 0).any()\n",
    "\n",
    "print(\"¬ø'year' tiene decimales?\", tiene_decimales(df['year'].dropna()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673ca3c",
   "metadata": {},
   "source": [
    "Se verifica que year no tiene desimales, por lo tanto se cambia su tipo de dato a entero (int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tiene_decimales(df['year'].dropna()):\n",
    "    df['year'] = df['year'].astype('Int64')  # acepta nulos (NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c642a8",
   "metadata": {},
   "source": [
    "**An√°lisis de posting_date:**  \n",
    "Para tener una certeza de que rango de fechas se estan por utilizar en el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2651da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "# Asegurarse de que 'posting_date' sea datetime, con zona horaria UTC\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'], errors='coerce', utc=True)\n",
    "\n",
    "# Convertir de datetime con zona horaria a sin zona horaria\n",
    "df['posting_date'] = df['posting_date'].dt.tz_convert(None)\n",
    "\n",
    "# Verificar tipo final\n",
    "print(df['posting_date'].dtype)\n",
    "\n",
    "# An√°lisis\n",
    "print(\"Fecha m√≠nima:\", df['posting_date'].min())\n",
    "print(\"Fecha m√°xima:\", df['posting_date'].max())\n",
    "print(\"Cantidad de fechas √∫nicas:\", df['posting_date'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b9013",
   "metadata": {},
   "source": [
    "Se comprueba que la cantidad de publicaciones abarca aproximadamente un mes. Esto es un periodo relativamente corto, m√°s para un mercado como el estadounidense que tiene una inflaci√≥n muy baja, como as√≠ tambi√©n estabilidad en tasas de inter√©s y disponibilidad de cr√©dito; por lo que se asumir√° que un veh√≠culo publicado al inicio del rango de fechas  de \"posting\", se encuentra en una situaci√≥n econ√≥mica casi igual que al final del rango.\n",
    "Asumiendo esto, se procede decide eliminar el campo \"posting_date\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622aee3d",
   "metadata": {},
   "source": [
    "**Eliminaci√≥n de columnas irrelevantes:**  \n",
    "Se eliminan los campos:\n",
    "1. los que tienen URLs, textos largos o son todas nulls. En este ultimo caso, solo se trata de **country**, pero se sabe que todos los datos son de veh√≠culos publicados en los **Estados Unidos**.  \n",
    "2. **VIN** que ser√≠a como el registro del automotor, ya que simplemente es un identificador que no es relevante para el an√°lisis y modelado.  \n",
    "3. **lat** y **long** que ser√≠an la latitud y longitud en donde se realizan los posteos, ya que esto es irrelevante para el modelado y en todo caso, tambien se cuenta con el campo *state (estado)* que permitir√≠a hacer una divisi√≥n de las publicaciones m√°s interesante y s√≠ ser√≠a *relevante* para el modelado. \n",
    "4. **region** porque ya se tiene un dato muy parecido que es el estado (state) y de hecho, la regi√≥n es una divisi√≥n hecha por Criglist.com para poder mostrar los anuncios correctamente.\n",
    "5. **posting_date** por los resultados de su an√°lisis.\n",
    "6. **id** porque es simplemente un identificador √∫nico, sin valor predictivo. Si lo dej√°s, el modelo puede memorizar registros, generando overfitting sin aportar nada real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['url', 'region_url', 'image_url', 'description', 'VIN', 'county', 'lat', 'long', 'region', 'posting_date', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ad5b2",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 3. **AN√ÅLISIS DE CARACTERISTICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13334a3d",
   "metadata": {},
   "source": [
    "### 3.1. **VERIFICAR VALORES NULOS Y PERDIDOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0753fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de valores nulos en el DataFrame\n",
    "def resumen_nulos(df):\n",
    "    total_nulos = df.isnull().sum()\n",
    "    porcentaje_nulos = (total_nulos / len(df)) * 100\n",
    "    resumen = pd.DataFrame({\n",
    "        'Nulos': total_nulos,\n",
    "        '% Nulos': porcentaje_nulos\n",
    "    })\n",
    "    resumen = resumen[resumen['Nulos'] > 0]\n",
    "    resumen = resumen.sort_values(by='% Nulos', ascending=False)\n",
    "    return resumen\n",
    "\n",
    "# Mostrar el resumen\n",
    "resumen_nulos(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788ed5f",
   "metadata": {},
   "source": [
    "### 3.2. **VALORES NUM√âRICOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eda0aa",
   "metadata": {},
   "source": [
    "| Columna      | % Nulos | Descripci√≥n              | Acci√≥n correctiva          |\n",
    "| ------------ | ------- | ------------------------ | -------------------------- |\n",
    "| **odometer** | 1.03%   | Kilometraje del veh√≠culo | Completar con **mediana**  |\n",
    "| **year**     | 0.28%   | A√±o de fabricaci√≥n       | Completar con **mediana**  |\n",
    "\n",
    "Justificaci√≥n:\n",
    "* Ambas columnas tienen nulos en un porcentaje muy bajo.\n",
    "* Dado que son variables continuas, la mediana es la mejor opci√≥n para evitar sesgos por outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bf62b",
   "metadata": {},
   "source": [
    "### 3.3. **VALORES CATEG√ìRICOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf845d5",
   "metadata": {},
   "source": [
    "| Columna           | % Nulos | Descripci√≥n                                | Importancia para el modelo | Acci√≥n correctiva sugerida                          |\n",
    "| ----------------- | ------- | ------------------------------------------ | -------------------------- | --------------------------------------------------- |\n",
    "| **manufacturer**  | 4.13%   | Marca del fabricante                       | Muy alta                   | **Eliminar filas con nulos** (clave para el modelo) |\n",
    "| **model**         | 1.24%   | Modelo espec√≠fico                          | Alta                       | Completar con **\"unknown\"**                         |\n",
    "| **condition**     | 40.78%  | Estado del veh√≠culo                        | Alta                       | Completar con **\"unknown\"**                         |\n",
    "| **cylinders**     | 41.62%  | Cantidad de cilindros                      | Media-alta                 | Completar con **\"unknown\"**                         |\n",
    "| **drive**         | 30.59%  | Tracci√≥n (FWD, RWD, 4WD)                   | Media                      | Completar con **\"unknown\"**                         |\n",
    "| **paint\\_color**  | 30.50%  | Color de la pintura                        | Baja                       | Completar con **\"unknown\"**                         |\n",
    "| **type**          | 21.75%  | Tipo de veh√≠culo (SUV, sedan, truck, etc.) | Media                      | Completar con **\"unknown\"**                         |\n",
    "| **title\\_status** | 1.93%   | Estado del t√≠tulo (clean, salvage, etc.)   | Alta                       | Completar con **moda**                              |\n",
    "| **fuel**          | 0.71%   | Tipo de combustible                        | Alta                       | Completar con **moda**                              |\n",
    "| **transmission**  | 0.60%   | Tipo de transmisi√≥n                        | Alta                       | Completar con **moda**                              |\n",
    "\n",
    "Justificaci√≥n:\n",
    "* Las columnas con menos del 5% de nulos (como fuel, transmission, title_status) son candidatas fuertes a completarse con la moda porque el valor m√°s frecuente suele ser representativo.\n",
    "* Las columnas con m√°s del 20% de nulos y que son categ√≥ricas no ordinales (condition, cylinders, drive, paint_color, type, model) pueden completarse con un valor neutro como \"unknown\" para no perder registros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92917d",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 4. **MANEJO DE VALORES FALTANTES Y AN√ìMALOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234690c4",
   "metadata": {},
   "source": [
    "### 4.1. **MANEJO DE VALORES FALTANTES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna \"size\" con demasiados nulos\n",
    "df.drop(columns=['size'], inplace=True)\n",
    "\n",
    "# Eliminar filas con manufacturer nulo (muy pocas)\n",
    "df = df[df['manufacturer'].notnull()]\n",
    "\n",
    "# Completar con 'unknown' en columnas categ√≥ricas relevantes\n",
    "cols_unknown = ['cylinders', 'condition', 'drive', 'paint_color', 'type', 'model']\n",
    "df[cols_unknown] = df[cols_unknown].fillna('unknown')\n",
    "\n",
    "# Completar con moda las columnas categ√≥ricas\n",
    "cols_moda = ['title_status', 'fuel', 'transmission']\n",
    "for col in cols_moda:\n",
    "    moda = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(moda)\n",
    "\n",
    "# Completar num√©ricas con mediana las columnas num√©ricas\n",
    "cols_mediana = ['odometer', 'year']\n",
    "for col in cols_mediana:\n",
    "    mediana = df[col].median()\n",
    "    df[col] = df[col].fillna(mediana)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb3cc40",
   "metadata": {},
   "source": [
    "Una vez realizada la depuraci√≥n y manejo de valores faltantes, conviene hacer un .info para verificar como quedaron las columnas y su integridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3920009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f14f5f",
   "metadata": {},
   "source": [
    "### 4.2. **DETECCI√ìN Y MANEJO DE OUTLIERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d2db5",
   "metadata": {},
   "source": [
    "Primero se debe detectar los outliers. Estos son facilmente visualizables con un boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['price'])\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df['odometer'])\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df['year'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0dedf",
   "metadata": {},
   "source": [
    "Con respecto a la columna price, es imprescindible aplicar la eliminaci√≥n de outliers fijando un umbral para precios fuera del rango $500 - $2.000.000. Esto es porque:  \n",
    "| Corte               | Motivo                                                                      |\n",
    "| ------------------- | --------------------------------------------------------------------------- |\n",
    "| `price < 1000`       | Precios demasiado bajos ‚Üí autos posiblemente no reales o datos mal cargados |\n",
    "| `price > 200,000` | Excesivamente altos para el contexto de Craigslist (veh√≠culos normales)     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Antes del filtrado:\", len(df))\n",
    "df = df[(df['price'] >= 1000) & (df['price'] <= 200_000)]\n",
    "print(\"Despu√©s del filtrado:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437cb6b",
   "metadata": {},
   "source": [
    "Con respecto a year y odometer, se realiza el sigeuinte histograma para relacionarlos y luego truncar los datos de manera m√°s justificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['year'], df['odometer'], alpha=0.1)\n",
    "plt.title(\"Relaci√≥n entre A√±o de fabricaci√≥n y Kilometraje\")\n",
    "plt.xlabel(\"A√±o (year)\")\n",
    "plt.ylabel(\"Kilometraje (odometer)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a32cf",
   "metadata": {},
   "source": [
    "Como se puede ver en el histograma, existen veh√≠culos con el odometro por encima de 4 millones de kil√≥metros... esto es irreal. Como as√≠ tambien se ve autos muy viejos, como por ejemplo de 1940 para atr√°s.  \n",
    "\n",
    "Cortes a realizar:\n",
    "- Eliminar veh√≠culos con kilometraje mayor a 4 millones\n",
    "- Eliminar veh√≠culos anteriores a 1940 (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7489a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Antes del filtrado:\", len(df))\n",
    "df = df[(df['odometer'] <= 1_000_000) & (df['year'] >= 1940)]\n",
    "print(\"Despu√©s del filtrado:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71698ebb",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 5. **INGENIER√çA DE CARACTER√çSTICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978d86e",
   "metadata": {},
   "source": [
    "### 5.1. **AN√ÅLISIS DE CARDINALIDAD DE VARIABLES CATEG√ìRICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47fa2e7",
   "metadata": {},
   "source": [
    "Antes de hacer una codificaci√≥n, es necesario saber la situaci√≥n de las variables categr√≠cas, para eso es menester usar el siguiente gr√°fico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas categ√≥ricas\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "# Contar valores √∫nicos por columna\n",
    "unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(unique_counts)\n",
    "\n",
    "# Paso 4: Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=unique_counts.values, y=unique_counts.index)\n",
    "plt.title('Cantidad de valores √∫nicos por columna categ√≥rica')\n",
    "plt.xlabel('Cantidad de valores √∫nicos')\n",
    "plt.ylabel('Columnas categ√≥ricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3be2aa",
   "metadata": {},
   "source": [
    "Como se puede observar en el diagrama de barras, model tiene una gran cardinalidad. Por lo tanto, se debe agrupar los valores por frecuencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = df['model'].value_counts().nlargest(100).index\n",
    "df['model_grouped'] = df['model'].apply(lambda x: x if x in top_models else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db991ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la cantidad de veh√≠culos por modelo agrupado\n",
    "model_counts = df['model_grouped'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Mostrar los primeros 100 modelos\n",
    "print(model_counts.head(100))\n",
    "\n",
    "# Filtrar el top 100\n",
    "top_100_models = model_counts.head(100)\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(12, 18))  # M√°s alto para que no se amontonen las etiquetas\n",
    "sns.barplot(x=top_100_models.values, y=top_100_models.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb50e9",
   "metadata": {},
   "source": [
    "Una vez que se logr√≥ tratar a la caracter√≠stica model, se procede a analizar las dem√°s caracteristicas que tienen mucha menos cardinalidad, por lo que visualmente se puede ver si los datos son consistentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a analizar\n",
    "cat_cols = ['manufacturer', 'type', 'paint_color', 'cylinders', 'condition', \n",
    "            'title_status', 'fuel', 'drive', 'transmission']\n",
    "\n",
    "# Mostrar valores √∫nicos y frecuencias por columna\n",
    "for col in cat_cols:\n",
    "    print(f\"\\nüìå Columna: {col}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(df[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58713a00",
   "metadata": {},
   "source": [
    "### 5.2. **NUEVAS CARACTER√çSTICAS DERIVADAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdcf69c",
   "metadata": {},
   "source": [
    "Se generar√°n las siguientes nuevas caracter√≠sticas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44129254",
   "metadata": {},
   "source": [
    "| Nueva columna       | C√≥mo se calcula                                                          | Justificaci√≥n                                 |\n",
    "| ------------------- | ------------------------------------------------------------------------ | --------------------------------------------- |\n",
    "| `vehicle_age`       | `vehicle_age = 2021 - year` *(ya que posting\\_date era abril/mayo 2021)* | Edad del veh√≠culo es mejor que a√±o bruto      |\n",
    "| `cylinders_num`     | Extraer n√∫mero de `cylinders` (usar regex o split)                       | Transforma texto a n√∫mero utilizable          |\n",
    "| `is_automatic`      | `1` si transmisi√≥n es autom√°tica, `0` si manual                          | M√°s directo para modelo                       |\n",
    "| `is_clean_title`    | `1` si `title_status == \"clean\"`, `0` si no                              | T√≠tulo limpio suele aumentar el precio        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4395eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. VEHICLE AGE (edad del veh√≠culo)\n",
    "df['vehicle_age'] = 2021 - df['year']\n",
    "\n",
    "# 2. CYLINDERS_NUM (extracci√≥n e imputaci√≥n con mediana)\n",
    "df['cylinders_num'] = df['cylinders'].str.extract(r'(\\d+)').astype(float)\n",
    "mediana_cyl = df['cylinders_num'].median()\n",
    "df['cylinders_num'] = df['cylinders_num'].fillna(mediana_cyl)\n",
    "\n",
    "# 3. IS_AUTOMATIC\n",
    "def map_transmission(value):\n",
    "    if value == 'automatic':\n",
    "        return 1\n",
    "    elif value == 'manual':\n",
    "        return 0\n",
    "    else:  # 'other' o desconocido\n",
    "        return -1\n",
    "\n",
    "df['is_automatic'] = df['transmission'].apply(map_transmission)\n",
    "\n",
    "# 4. IS_CLEAN_TITLE\n",
    "df['is_clean_title'] = df['title_status'].apply(lambda x: 1 if x == 'clean' else 0)\n",
    "\n",
    "# VERIFICACI√ìN DE LOS CAMBIOS\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf4589",
   "metadata": {},
   "source": [
    "### 5.3. **CODIFICACI√ìN DE VARIABLES CATEG√ìRICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61298b",
   "metadata": {},
   "source": [
    "Se utilizar√° One-Hot Encoding para todas las variables categ√≥ricas porque son nominales, no ordinales.  \n",
    "Por otro lado, se eliminar√°n las columnas transmission, model y cylinders porque ya se ubtuvo su veris√≥n no categ√≥rica (is_automatic, cylinders_num). En el caso de model, se obtuvo model_group que debe ser codificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas innecesarias que ya fueron codificadas\n",
    "df.drop(columns=['transmission', 'cylinders', 'model'], inplace=True)\n",
    "\n",
    "cat_cols = [\n",
    "    'manufacturer',\n",
    "    'model_grouped',\n",
    "    'condition',\n",
    "    'fuel',\n",
    "    'title_status',\n",
    "    'drive',\n",
    "    'type',\n",
    "    'paint_color',\n",
    "    'state'\n",
    "]\n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Ver resultado\n",
    "print(\"Shape final del dataset:\", df_encoded.shape)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICACI√ìN DE LOS CAMBIOS\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb294ce",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 6. **MODELADO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d537e60",
   "metadata": {},
   "source": [
    "### 6.1. **MODELADO SIMPLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e7ce0",
   "metadata": {},
   "source": [
    "#### 6.1.1. Modelos de valizaci√≥n cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe00c6",
   "metadata": {},
   "source": [
    "A modo de ir respondiendo las preguntas que se plantearon al inicio del proyecto, se realizar√° un diagrama de calor para ver la correlaci√≥n de las variables num√©ricas con respecto a price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo columnas num√©ricas\n",
    "numeric_cols = df_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Calcular la matriz de correlaci√≥n\n",
    "correlation_matrix = df_encoded[numeric_cols].corr()\n",
    "\n",
    "# Extraer solo la fila/columna de 'price'\n",
    "correlation_with_price = correlation_matrix['price'].sort_values(ascending=False)\n",
    "\n",
    "# Mostrar top correlaciones positivas y negativas\n",
    "print(\"üîù Variables m√°s positivamente correlacionadas con el precio:\")\n",
    "print(correlation_with_price.head(10))\n",
    "\n",
    "print(\"\\nüîª Variables m√°s negativamente correlacionadas con el precio:\")\n",
    "print(correlation_with_price.tail(10))\n",
    "\n",
    "# (Opcional) Gr√°fico de calor completo\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix[['price']].sort_values(by='price', ascending=False), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlaci√≥n de variables num√©ricas con el precio\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0d221",
   "metadata": {},
   "source": [
    "Como se puede visualizar, hay varias variables muy cercanas a 0, lo que indica una correlaci√≥n muy baja, especialmente is_clean_title, por ejemplo, pero esto no es tan determinante porque no aportan mucho solas. En convinaci√≥n con las otras variables, muy probablemente si aporten. Por otro lado, ninguna variables tiene una correlaci√≥n por encima de 0,5. Esto indica que las vatiables tienen una participaci√≥n en conjunto. Es decir, se reafirma lo que pasa con is_clea_tittle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = df_encoded.drop(columns=['price'])\n",
    "y = df_encoded['price']\n",
    "\n",
    "# 2. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Entrenar modelo base\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predecir\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. M√©tricas\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"üìä MAE:  {mae:.2f}\")\n",
    "print(f\"üìä RMSE: {rmse:.2f}\")\n",
    "print(f\"üìä R¬≤:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979a9d3",
   "metadata": {},
   "source": [
    "#### 6.1.2. Ajuste de hiperpar√°metros para obtener los mejores modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820d073",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è¬°ATENCI√ìN!  \n",
    "El Sigueinte bloque de c√≥digo corresponde a encontrar los mejores hiperpar√°metros usando GridSearchCV. Si no cuentas con una PC de altas prestaciones, este codigo puede demorar bastante y tener resultados que no ser√°n los mejores.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el modelo base\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Definir la grilla de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Configurar el GridSearch con validaci√≥n cruzada de 3 folds\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar b√∫squeda\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar mejores par√°metros y score\n",
    "print(\"üîç Mejores par√°metros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"üìâ Mejor RMSE (negativo): {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7fd310",
   "metadata": {},
   "source": [
    "Una vez ejecutado el bloque de c√≥digo anterior, se obtuvieron los sigueintes hiperpar√°metros con un RMSE (negativo) de -8920.4557:  \n",
    "\n",
    "max_depth: **None** (los otros par√°metros compensan el riesgo de overfitting)  \n",
    "max_features: **log2** (subconjunto reducido de columnas)  \n",
    "min_samples_leaf: **1** (las hohas del arbol tienen una sola muestra, es decir, una alta resoluci√≥n)  \n",
    "min_samples_split: **2** (las ramas se dividen con solo 2 muestras)  \n",
    "n_estimators: **100** (se usan 100 √°rboles)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ee9cd",
   "metadata": {},
   "source": [
    "Se procede a ejecutar el entrenamiento con los mejores par√°metros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66597796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir X e y\n",
    "X = df_encoded.drop(columns=['price'])\n",
    "y = df_encoded['price']\n",
    "\n",
    "# 2. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Entrenar modelo optimizado\n",
    "modelo_optimo = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "modelo_optimo.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predecir\n",
    "y_pred = modelo_optimo.predict(X_test)\n",
    "\n",
    "# 5. M√©tricas\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"üìä MAE:  {mae:.2f}\")\n",
    "print(f\"üìä RMSE: {rmse:.2f}\")\n",
    "print(f\"üìä R¬≤:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7b99e",
   "metadata": {},
   "source": [
    "#### 6.1.3. Trazar curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ebc79e",
   "metadata": {},
   "source": [
    "Se debe comprender como evoluciona el rendimiento del modelo a medida que se agregan m√°s datos al entrenamiento y luego saber si se necesitan m√°s datos o hay un sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import LearningCurveDisplay\n",
    "\n",
    "# 1. Crear el modelo base\n",
    "estimator = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Definir el m√©todo de validaci√≥n cruzada\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Trazar la curva de aprendizaje usando R¬≤\n",
    "LearningCurveDisplay.from_estimator(\n",
    "    estimator=estimator,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),  # 5 puntos de entrenamiento: 10% a 100%\n",
    ")\n",
    "\n",
    "plt.title(\"Curva de Aprendizaje - Random Forest (R¬≤)\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54566e07",
   "metadata": {},
   "source": [
    "Se observa que el R¬≤ de Train es mucho mayor que Test. Esto significa que el modelo est√° sobreajustado (aprende demasiado bien los datos de entrenamiento y generaliza peor).\n",
    "Se observa que a mayor tama√±o de entrenamiento, mejora el R¬≤ de Test, es decir, m√°s datos ayudan a generalizar mejor.\n",
    "En general, el modelo tiene buena capacidad predictiva, pero hay espacio para mejorar la generalizaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa5d90",
   "metadata": {},
   "source": [
    "#### 6.1.4. Importancia de las caracter√≠sticas (Feature Importance) de RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793e77b",
   "metadata": {},
   "source": [
    "En RandomForestRegressor, la importancia de una caracter√≠stica se mide como la reducci√≥n total de error (por ejemplo, MSE) atribuible a cada feature, promediada entre todos los √°rboles del bosque.  \n",
    "El resultado es un valor entre 0 y 1 para cada feature. Cuanto mayor el valor, m√°s importante fue esa columna en las decisiones del modelo. Para obtener esto se debe ejecutar el siguiente bloque de c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = modelo_optimo.feature_importances_\n",
    "columnas = X_train.columns\n",
    "\n",
    "# Crear un DataFrame ordenado\n",
    "importancias_df = pd.DataFrame({\n",
    "    'Feature': columnas,\n",
    "    'Importancia': importancia\n",
    "}).sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "# Mostrar las 30 caracter√≠sticas m√°s importantes ordenadas\n",
    "top_importancias = importancias_df.head(30)\n",
    "\n",
    "for i, row in top_importancias.iterrows():\n",
    "    print(f\"{i+1:2d}. {row['Feature']:40s} --> {row['Importancia']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(top_importancias['Feature'][::-1], top_importancias['Importancia'][::-1], color='skyblue')\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.title(\"Top 30 caracter√≠sticas m√°s importantes seg√∫n Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d65cb8",
   "metadata": {},
   "source": [
    "**Conclusiones del an√°lisis de importancia de caracter√≠sticas:**  \n",
    "\n",
    "**Dominio de pocas variables:** odometer (0.1591), year (0.1382) y vehicle_age (0.1369) concentran una gran parte de la importancia total.  \n",
    "**Desbalance de relevancia:** Desde la posici√≥n 4 en adelante, la importancia de las caracter√≠sticas cae dr√°sticamente.   \n",
    "**Alta dimensionalidad:** Muchas columnas apenas aportan entre 0.005 y 0.01, lo cual indica que son poco √∫tiles para la predicci√≥n.  \n",
    "**Redundancias:** Algunas columnas parecen variantes de una misma informaci√≥n. Ej: year y vehicle_age, model_grouped_unknown y model_grouped_other.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccddcc",
   "metadata": {},
   "source": [
    "#### 6.1.5. Mejoras en base al Feature Importance y la curva de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar variables de baja importancia\n",
    "columnas_a_eliminar = importancias_df[importancias_df['Importancia'] < 0.005]['Feature']\n",
    "X_train_filtrado = X_train.drop(columns=columnas_a_eliminar)\n",
    "X_test_filtrado = X_test.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Eliminar columna 'year' si existe\n",
    "for df in [X_train_filtrado, X_test_filtrado]:\n",
    "    if 'year' in df.columns:\n",
    "        df.drop(columns='year', inplace=True)\n",
    "\n",
    "# Combinar 'model_grouped_unknown' y 'model_grouped_other' en 'model_grouped_misc'\n",
    "for df in [X_train_filtrado, X_test_filtrado]:\n",
    "    if 'model_grouped_unknown' in df.columns and 'model_grouped_other' in df.columns:\n",
    "        df['model_grouped_misc'] = df['model_grouped_unknown'] + df['model_grouped_other']\n",
    "        df.drop(columns=['model_grouped_unknown', 'model_grouped_other'], inplace=True)\n",
    "    elif 'model_grouped_unknown' in df.columns:\n",
    "        df.rename(columns={'model_grouped_unknown': 'model_grouped_misc'}, inplace=True)\n",
    "    elif 'model_grouped_other' in df.columns:\n",
    "        df.rename(columns={'model_grouped_other': 'model_grouped_misc'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ddc3e8",
   "metadata": {},
   "source": [
    "Aplicaremos nuevamente RandomForestRegressor pero teniendo en cuenta de evitar el sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8895f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Entrenar modelo con par√°metros para reducir sobreajuste\n",
    "# Antes los par√°metros eran:\n",
    "#    n_estimators=100,\n",
    "#    max_depth=None,\n",
    "#    max_features='log2',\n",
    "#    min_samples_leaf=1,\n",
    "#    min_samples_split=2,\n",
    "#    random_state=42\n",
    "\n",
    "modelo_regularizado = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "modelo_regularizado.fit(X_train_filtrado, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred = modelo_regularizado.predict(X_train_filtrado)\n",
    "y_test_pred = modelo_regularizado.predict(X_test_filtrado)\n",
    "\n",
    "# M√©tricas\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"=== M√©tricas de Entrenamiento ===\")\n",
    "print(f\"MAE:  {mae_train:.2f}\")\n",
    "print(f\"RMSE: {rmse_train:.2f}\")\n",
    "print(f\"R¬≤:   {r2_train:.4f}\")\n",
    "\n",
    "print(\"\\n=== M√©tricas de Test ===\")\n",
    "print(f\"MAE:  {mae_test:.2f}\")\n",
    "print(f\"RMSE: {rmse_test:.2f}\")\n",
    "print(f\"R¬≤:   {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a2b4a",
   "metadata": {},
   "source": [
    "### 6.2. **MODELADO DE CONJUNTOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cac68e",
   "metadata": {},
   "source": [
    "#### 6.2.1. Obtener un segundo modelo con otro m√©todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476a8de",
   "metadata": {},
   "source": [
    "Para esto, se har√° uso de XGBoost. Primero se debe ejecutar *\"pip install xgboost\"* para instalar XGBoost en tu sistema.  \n",
    "Luego se procede con el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d69d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "modelo_xgb = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09456597",
   "metadata": {},
   "source": [
    "#### 6.2.2. Combinando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cf5cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849814f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = (y_pred_rf + y_pred_xgb) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d9be1c",
   "metadata": {},
   "source": [
    "### 6.3. **PREDICCI√ìN FINAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4abac",
   "metadata": {},
   "source": [
    "#### 6.3.1. Predecir y evaluar resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214a0bb",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 7. **CONCLUSI√ìN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce688f",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 8. **PR√ìXIMAS L√çNEAS**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
