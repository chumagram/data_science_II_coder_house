{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a74cb9a",
   "metadata": {},
   "source": [
    "# **Proyecto final de Ciencia de Datos II - Coder House**\n",
    "# ~ Modelo de predicción de precios de vehículos ~\n",
    "Estudiante: **Gonzalo Leonel Gramajo**  \n",
    "Comisión: **75690**  \n",
    "Documento: **40441349**  \n",
    "Año: **2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20828f05",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 1. **INTRODUCCIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05b78a",
   "metadata": {},
   "source": [
    "Este notebook corresponde al trabajo final del curso \"CIENCIA DE DATOS II\" de Coder House.  \n",
    "Está basado en un dataset de ventas de autos rescatado desde Keegle. Este conjunto de datos incluye todas las publicaciones de vehículos usados ​​dentro de los Estados Unidos en Craigslist.com.\n",
    "Es importante resaltar que se cuenta con 426 mil lineas y el archivo ocupa 1.45 GB de almacenamiento, por lo que un archivo de tal tamaño no se peude subir a GitHub. Dado esto, el archivo .csv se puede encontrar disponible en Google Drive y Kaggle.\n",
    "\n",
    "### **Dataset**\n",
    "Used Cars Dataset - Vehicles listings from Craigslist.org.  \n",
    "Enlace web a Kaggle: https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data  \n",
    "Enlace web a Google Drive: https://drive.google.com/file/d/1uQ_YhqBimI46j5W-EgSwkjZvpFt87ejt/view?usp=sharing\n",
    "\n",
    "### **Objetivo general**\n",
    "*Lograr un modelo predictivo que logre inferir automáticamente el precio de los vehículos acorde a las caracteristicas más relevantes de los mismos.*\n",
    "\n",
    "### **Objetivos específicos**\n",
    "* *Encontrar las variables de correlación principales con el precio del vehículo.*\n",
    "* *Lograr un primer modelo predictivo y evaluar su rendimiento.*\n",
    "* *Generar un modelo predictivo optimizado con métricas maximizadas.*\n",
    "\n",
    "### **Preguntas de interés**\n",
    "\n",
    "1. ¿Los autos con menos kilometraje (odometer) tienden a ser más valorados?  \n",
    "1.1. ¿Cuál es la correlación entre el kilometraje (odometer) y el precio del vehículo?  \n",
    "1.2. ¿Existe un umbral de kilometraje a partir del cual el valor del vehículo cae significativamente?  \n",
    "  \n",
    "2. ¿Cómo varía el precio de los vehículos según su marca/fabricante?  \n",
    "2.1. ¿Qué marcas presentan mayor dispersión de precios en sus publicaciones?  \n",
    "2.2. ¿Existen marcas cuyos vehículos están consistentemente sobrevalorados o subvalorados respecto a la media general?    \n",
    "  \n",
    "3. ¿Los vehículos con año de fabricación menor, se venden exponencialmente mas caros?  \n",
    "3.1. ¿Cómo varía el precio medio de los vehículos según el año de fabricación?  \n",
    "3.2. ¿Se observa una depreciación lineal o no lineal del precio con el paso de los años?  \n",
    "   \n",
    "4. ¿Los Fabricantes con más publicaciones, son los que se acercan más a la media del precio?   \n",
    "4.1. ¿Los fabricantes con más publicaciones son de marcas nacionales?   \n",
    "4.2. ¿Los fabricantes nacionales tienen precios más bajos que otras marcas?   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d8cbd",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 2. **CARGA Y VERIFICACIÓN DE DATOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6bd38",
   "metadata": {},
   "source": [
    "### 2.1. **CARGA DE DATOS E IMPORTACIONES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3de20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herramientas principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Módulos de visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carga el archivo CSV en un DataFrame de pandas\n",
    "file_path = './vehicles.csv' # ruta al archivo CSV\n",
    "df = pd.read_csv(file_path) # leer el archivo CSV y conseguir un dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e4a44",
   "metadata": {},
   "source": [
    "Mostrar  las primeras 5 lineas del dataframe cargao para tener un pantallazo de que se trata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106bb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # mostrar los primeros 5 valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e727032",
   "metadata": {},
   "source": [
    "A simple vista y rápidamente se puede observar una gran cantidad de información que no es relevante para el objetivo, como ser las URLs. También se ve muchos NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1bf47",
   "metadata": {},
   "source": [
    "### 2.2. **REVISIÓN GENERAL Y LIMPIEZA INICIAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(\"\\n Cantidad de valores nulos por columna: \\n\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdefd9",
   "metadata": {},
   "source": [
    "**Revisar si year tiene decimales**. En la \"info\" del dataframe, se puede ver que year es de tipo float. Esto es algo extraño ya que suelen ser valores enteros, por lo tanto, se debe averiguar por qué esto es así. Puede ser que existan valores decimales o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03184387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para verificar si hay decimales en una columna\n",
    "def tiene_decimales(serie):\n",
    "    return (serie % 1 != 0).any()\n",
    "\n",
    "print(\"¿'year' tiene decimales?\", tiene_decimales(df['year'].dropna()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673ca3c",
   "metadata": {},
   "source": [
    "Se verifica que year no tiene desimales, por lo tanto se cambia su tipo de dato a entero (int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tiene_decimales(df['year'].dropna()):\n",
    "    df['year'] = df['year'].astype('Int64')  # acepta nulos (NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c642a8",
   "metadata": {},
   "source": [
    "**Análisis de posting_date:**  \n",
    "Para tener una certeza de que rango de fechas se estan por utilizar en el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2651da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "# Asegurarse de que 'posting_date' sea datetime, con zona horaria UTC\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'], errors='coerce', utc=True)\n",
    "\n",
    "# Convertir de datetime con zona horaria a sin zona horaria\n",
    "df['posting_date'] = df['posting_date'].dt.tz_convert(None)\n",
    "\n",
    "# Verificar tipo final\n",
    "print(df['posting_date'].dtype)\n",
    "\n",
    "# Análisis\n",
    "print(\"Fecha mínima:\", df['posting_date'].min())\n",
    "print(\"Fecha máxima:\", df['posting_date'].max())\n",
    "print(\"Cantidad de fechas únicas:\", df['posting_date'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b9013",
   "metadata": {},
   "source": [
    "Se comprueba que la cantidad de publicaciones abarca aproximadamente un mes. Esto es un periodo relativamente corto, más para un mercado como el estadounidense que tiene una inflación muy baja, como así también estabilidad en tasas de interés y disponibilidad de crédito; por lo que se asumirá que un vehículo publicado al inicio del rango de fechas  de \"posting\", se encuentra en una situación económica casi igual que al final del rango.\n",
    "Asumiendo esto, se procede decide eliminar el campo \"posting_date\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622aee3d",
   "metadata": {},
   "source": [
    "**Eliminación de columnas irrelevantes:**  \n",
    "Se eliminan los campos:\n",
    "1. los que tienen URLs, textos largos o son todas nulls. En este ultimo caso, solo se trata de **country**, pero se sabe que todos los datos son de vehículos publicados en los **Estados Unidos**.  \n",
    "2. **VIN** que sería como el registro del automotor, ya que simplemente es un identificador que no es relevante para el análisis y modelado.  \n",
    "3. **lat** y **long** que serían la latitud y longitud en donde se realizan los posteos, ya que esto es irrelevante para el modelado y en todo caso, tambien se cuenta con el campo *state (estado)* que permitiría hacer una división de las publicaciones más interesante y sí sería *relevante* para el modelado. \n",
    "4. **region** porque ya se tiene un dato muy parecido que es el estado (state) y de hecho, la región es una división hecha por Criglist.com para poder mostrar los anuncios correctamente.\n",
    "5. **posting_date** por los resultados de su análisis.\n",
    "6. **id** porque es simplemente un identificador único, sin valor predictivo. Si lo dejás, el modelo puede memorizar registros, generando overfitting sin aportar nada real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['url', 'region_url', 'image_url', 'description', 'VIN', 'county', 'lat', 'long', 'region', 'posting_date', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ad5b2",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 3. **ANÁLISIS DE CARACTERISTICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13334a3d",
   "metadata": {},
   "source": [
    "### 3.1. **VERIFICAR VALORES NULOS Y PERDIDOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0753fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de valores nulos en el DataFrame\n",
    "def resumen_nulos(df):\n",
    "    total_nulos = df.isnull().sum()\n",
    "    porcentaje_nulos = (total_nulos / len(df)) * 100\n",
    "    resumen = pd.DataFrame({\n",
    "        'Nulos': total_nulos,\n",
    "        '% Nulos': porcentaje_nulos\n",
    "    })\n",
    "    resumen = resumen[resumen['Nulos'] > 0]\n",
    "    resumen = resumen.sort_values(by='% Nulos', ascending=False)\n",
    "    return resumen\n",
    "\n",
    "# Mostrar el resumen\n",
    "resumen_nulos(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788ed5f",
   "metadata": {},
   "source": [
    "### 3.2. **VALORES NUMÉRICOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eda0aa",
   "metadata": {},
   "source": [
    "| Columna      | % Nulos | Descripción              | Acción correctiva          |\n",
    "| ------------ | ------- | ------------------------ | -------------------------- |\n",
    "| **odometer** | 1.03%   | Kilometraje del vehículo | Completar con **mediana**  |\n",
    "| **year**     | 0.28%   | Año de fabricación       | Completar con **mediana**  |\n",
    "\n",
    "Justificación:\n",
    "* Ambas columnas tienen nulos en un porcentaje muy bajo.\n",
    "* Dado que son variables continuas, la mediana es la mejor opción para evitar sesgos por outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bf62b",
   "metadata": {},
   "source": [
    "### 3.3. **VALORES CATEGÓRICOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf845d5",
   "metadata": {},
   "source": [
    "| Columna           | % Nulos | Descripción                                | Importancia para el modelo | Acción correctiva sugerida                          |\n",
    "| ----------------- | ------- | ------------------------------------------ | -------------------------- | --------------------------------------------------- |\n",
    "| **manufacturer**  | 4.13%   | Marca del fabricante                       | Muy alta                   | **Eliminar filas con nulos** (clave para el modelo) |\n",
    "| **model**         | 1.24%   | Modelo específico                          | Alta                       | Completar con **\"unknown\"**                         |\n",
    "| **condition**     | 40.78%  | Estado del vehículo                        | Alta                       | Completar con **\"unknown\"**                         |\n",
    "| **cylinders**     | 41.62%  | Cantidad de cilindros                      | Media-alta                 | Completar con **\"unknown\"**                         |\n",
    "| **drive**         | 30.59%  | Tracción (FWD, RWD, 4WD)                   | Media                      | Completar con **\"unknown\"**                         |\n",
    "| **paint\\_color**  | 30.50%  | Color de la pintura                        | Baja                       | Completar con **\"unknown\"**                         |\n",
    "| **type**          | 21.75%  | Tipo de vehículo (SUV, sedan, truck, etc.) | Media                      | Completar con **\"unknown\"**                         |\n",
    "| **title\\_status** | 1.93%   | Estado del título (clean, salvage, etc.)   | Alta                       | Completar con **moda**                              |\n",
    "| **fuel**          | 0.71%   | Tipo de combustible                        | Alta                       | Completar con **moda**                              |\n",
    "| **transmission**  | 0.60%   | Tipo de transmisión                        | Alta                       | Completar con **moda**                              |\n",
    "\n",
    "Justificación:\n",
    "* Las columnas con menos del 5% de nulos (como fuel, transmission, title_status) son candidatas fuertes a completarse con la moda porque el valor más frecuente suele ser representativo.\n",
    "* Las columnas con más del 20% de nulos y que son categóricas no ordinales (condition, cylinders, drive, paint_color, type, model) pueden completarse con un valor neutro como \"unknown\" para no perder registros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92917d",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 4. **MANEJO DE VALORES FALTANTES Y ANÓMALOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234690c4",
   "metadata": {},
   "source": [
    "### 4.1. **MANEJO DE VALORES FALTANTES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna \"size\" con demasiados nulos\n",
    "df.drop(columns=['size'], inplace=True)\n",
    "\n",
    "# Eliminar filas con manufacturer nulo (muy pocas)\n",
    "df = df[df['manufacturer'].notnull()]\n",
    "\n",
    "# Completar con 'unknown' en columnas categóricas relevantes\n",
    "cols_unknown = ['cylinders', 'condition', 'drive', 'paint_color', 'type', 'model']\n",
    "df[cols_unknown] = df[cols_unknown].fillna('unknown')\n",
    "\n",
    "# Completar con moda las columnas categóricas\n",
    "cols_moda = ['title_status', 'fuel', 'transmission']\n",
    "for col in cols_moda:\n",
    "    moda = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(moda)\n",
    "\n",
    "# Completar numéricas con mediana las columnas numéricas\n",
    "cols_mediana = ['odometer', 'year']\n",
    "for col in cols_mediana:\n",
    "    mediana = df[col].median()\n",
    "    df[col] = df[col].fillna(mediana)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb3cc40",
   "metadata": {},
   "source": [
    "Una vez realizada la depuración y manejo de valores faltantes, conviene hacer un .info para verificar como quedaron las columnas y su integridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3920009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f14f5f",
   "metadata": {},
   "source": [
    "### 4.2. **DETECCIÓN Y MANEJO DE OUTLIERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d2db5",
   "metadata": {},
   "source": [
    "Primero se debe detectar los outliers. Estos son facilmente visualizables con un boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['price'])\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df['odometer'])\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df['year'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0dedf",
   "metadata": {},
   "source": [
    "Con respecto a la columna price, es imprescindible aplicar la eliminación de outliers fijando un umbral para precios fuera del rango $500 - $2.000.000. Esto es porque:  \n",
    "| Corte               | Motivo                                                                      |\n",
    "| ------------------- | --------------------------------------------------------------------------- |\n",
    "| `price < 1000`       | Precios demasiado bajos → autos posiblemente no reales o datos mal cargados |\n",
    "| `price > 200,000` | Excesivamente altos para el contexto de Craigslist (vehículos normales)     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Antes del filtrado:\", len(df))\n",
    "df = df[(df['price'] >= 1000) & (df['price'] <= 200_000)]\n",
    "print(\"Después del filtrado:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437cb6b",
   "metadata": {},
   "source": [
    "Con respecto a year y odometer, se realiza el sigeuinte histograma para relacionarlos y luego truncar los datos de manera más justificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['year'], df['odometer'], alpha=0.1)\n",
    "plt.title(\"Relación entre Año de fabricación y Kilometraje\")\n",
    "plt.xlabel(\"Año (year)\")\n",
    "plt.ylabel(\"Kilometraje (odometer)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a32cf",
   "metadata": {},
   "source": [
    "Como se puede ver en el histograma, existen vehículos con el odometro por encima de 4 millones de kilómetros... esto es irreal. Como así tambien se ve autos muy viejos, como por ejemplo de 1940 para atrás.  \n",
    "\n",
    "Cortes a realizar:\n",
    "- Eliminar vehículos con kilometraje mayor a 4 millones\n",
    "- Eliminar vehículos anteriores a 1940 (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7489a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Antes del filtrado:\", len(df))\n",
    "df = df[(df['odometer'] <= 1_000_000) & (df['year'] >= 1940)]\n",
    "print(\"Después del filtrado:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71698ebb",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 5. **INGENIERÍA DE CARACTERÍSTICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978d86e",
   "metadata": {},
   "source": [
    "### 5.1. **ANÁLISIS DE CARDINALIDAD DE VARIABLES CATEGÓRICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47fa2e7",
   "metadata": {},
   "source": [
    "Antes de hacer una codificación, es necesario saber la situación de las variables categrícas, para eso es menester usar el siguiente gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas categóricas\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "# Contar valores únicos por columna\n",
    "unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(unique_counts)\n",
    "\n",
    "# Paso 4: Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=unique_counts.values, y=unique_counts.index)\n",
    "plt.title('Cantidad de valores únicos por columna categórica')\n",
    "plt.xlabel('Cantidad de valores únicos')\n",
    "plt.ylabel('Columnas categóricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3be2aa",
   "metadata": {},
   "source": [
    "Como se puede observar en el diagrama de barras, model tiene una gran cardinalidad. Por lo tanto, se debe agrupar los valores por frecuencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = df['model'].value_counts().nlargest(100).index\n",
    "df['model_grouped'] = df['model'].apply(lambda x: x if x in top_models else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db991ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la cantidad de vehículos por modelo agrupado\n",
    "model_counts = df['model_grouped'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Mostrar los primeros 100 modelos\n",
    "print(model_counts.head(100))\n",
    "\n",
    "# Filtrar el top 100\n",
    "top_100_models = model_counts.head(100)\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(12, 18))  # Más alto para que no se amontonen las etiquetas\n",
    "sns.barplot(x=top_100_models.values, y=top_100_models.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb50e9",
   "metadata": {},
   "source": [
    "Una vez que se logró tratar a la característica model, se procede a analizar las demás caracteristicas que tienen mucha menos cardinalidad, por lo que visualmente se puede ver si los datos son consistentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a analizar\n",
    "cat_cols = ['manufacturer', 'type', 'paint_color', 'cylinders', 'condition', \n",
    "            'title_status', 'fuel', 'drive', 'transmission']\n",
    "\n",
    "# Mostrar valores únicos y frecuencias por columna\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n📌 Columna: {col}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(df[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58713a00",
   "metadata": {},
   "source": [
    "### 5.2. **NUEVAS CARACTERÍSTICAS DERIVADAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdcf69c",
   "metadata": {},
   "source": [
    "Se generarán las siguientes nuevas características:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44129254",
   "metadata": {},
   "source": [
    "| Nueva columna       | Cómo se calcula                                                          | Justificación                                 |\n",
    "| ------------------- | ------------------------------------------------------------------------ | --------------------------------------------- |\n",
    "| `vehicle_age`       | `vehicle_age = 2021 - year` *(ya que posting\\_date era abril/mayo 2021)* | Edad del vehículo es mejor que año bruto      |\n",
    "| `cylinders_num`     | Extraer número de `cylinders` (usar regex o split)                       | Transforma texto a número utilizable          |\n",
    "| `is_automatic`      | `1` si transmisión es automática, `0` si manual                          | Más directo para modelo                       |\n",
    "| `is_clean_title`    | `1` si `title_status == \"clean\"`, `0` si no                              | Título limpio suele aumentar el precio        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4395eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. VEHICLE AGE (edad del vehículo)\n",
    "df['vehicle_age'] = 2021 - df['year']\n",
    "\n",
    "# 2. CYLINDERS_NUM (extracción e imputación con mediana)\n",
    "df['cylinders_num'] = df['cylinders'].str.extract(r'(\\d+)').astype(float)\n",
    "mediana_cyl = df['cylinders_num'].median()\n",
    "df['cylinders_num'] = df['cylinders_num'].fillna(mediana_cyl)\n",
    "\n",
    "# 3. IS_AUTOMATIC\n",
    "def map_transmission(value):\n",
    "    if value == 'automatic':\n",
    "        return 1\n",
    "    elif value == 'manual':\n",
    "        return 0\n",
    "    else:  # 'other' o desconocido\n",
    "        return -1\n",
    "\n",
    "df['is_automatic'] = df['transmission'].apply(map_transmission)\n",
    "\n",
    "# 4. IS_CLEAN_TITLE\n",
    "df['is_clean_title'] = df['title_status'].apply(lambda x: 1 if x == 'clean' else 0)\n",
    "\n",
    "# VERIFICACIÓN DE LOS CAMBIOS\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf4589",
   "metadata": {},
   "source": [
    "### 5.3. **CODIFICACIÓN DE VARIABLES CATEGÓRICAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61298b",
   "metadata": {},
   "source": [
    "Se utilizará One-Hot Encoding para todas las variables categóricas porque son nominales, no ordinales.  \n",
    "Por otro lado, se eliminarán las columnas transmission, model y cylinders porque ya se ubtuvo su verisón no categórica (is_automatic, cylinders_num). En el caso de model, se obtuvo model_group que debe ser codificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas innecesarias que ya fueron codificadas\n",
    "df.drop(columns=['transmission', 'cylinders', 'model'], inplace=True)\n",
    "\n",
    "cat_cols = [\n",
    "    'manufacturer',\n",
    "    'model_grouped',\n",
    "    'condition',\n",
    "    'fuel',\n",
    "    'title_status',\n",
    "    'drive',\n",
    "    'type',\n",
    "    'paint_color',\n",
    "    'state'\n",
    "]\n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Ver resultado\n",
    "print(\"Shape final del dataset:\", df_encoded.shape)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICACIÓN DE LOS CAMBIOS\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb294ce",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 6. **MODELADO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d537e60",
   "metadata": {},
   "source": [
    "### 6.1. **MODELADO SIMPLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e7ce0",
   "metadata": {},
   "source": [
    "#### 6.1.1. Modelos de valización cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe00c6",
   "metadata": {},
   "source": [
    "A modo de ir respondiendo las preguntas que se plantearon al inicio del proyecto, se realizará un diagrama de calor para ver la correlación de las variables numéricas con respecto a price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo columnas numéricas\n",
    "numeric_cols = df_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = df_encoded[numeric_cols].corr()\n",
    "\n",
    "# Extraer solo la fila/columna de 'price'\n",
    "correlation_with_price = correlation_matrix['price'].sort_values(ascending=False)\n",
    "\n",
    "# Mostrar top correlaciones positivas y negativas\n",
    "print(\"🔝 Variables más positivamente correlacionadas con el precio:\")\n",
    "print(correlation_with_price.head(10))\n",
    "\n",
    "print(\"\\n🔻 Variables más negativamente correlacionadas con el precio:\")\n",
    "print(correlation_with_price.tail(10))\n",
    "\n",
    "# (Opcional) Gráfico de calor completo\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix[['price']].sort_values(by='price', ascending=False), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlación de variables numéricas con el precio\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0d221",
   "metadata": {},
   "source": [
    "Como se puede visualizar, hay varias variables muy cercanas a 0, lo que indica una correlación muy baja, especialmente is_clean_title, por ejemplo, pero esto no es tan determinante porque no aportan mucho solas. En convinación con las otras variables, muy probablemente si aporten. Por otro lado, ninguna variables tiene una correlación por encima de 0,5. Esto indica que las vatiables tienen una participación en conjunto. Es decir, se reafirma lo que pasa con is_clea_tittle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = df_encoded.drop(columns=['price'])\n",
    "y = df_encoded['price']\n",
    "\n",
    "# 2. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Entrenar modelo base\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predecir\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Métricas\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"📊 MAE:  {mae:.2f}\")\n",
    "print(f\"📊 RMSE: {rmse:.2f}\")\n",
    "print(f\"📊 R²:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979a9d3",
   "metadata": {},
   "source": [
    "#### 6.1.2. Ajuste de hiperparámetros para obtener los mejores modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820d073",
   "metadata": {},
   "source": [
    "**⚠️¡ATENCIÓN!  \n",
    "El Sigueinte bloque de código corresponde a encontrar los mejores hiperparámetros usando GridSearchCV. Si no cuentas con una PC de altas prestaciones, este codigo puede demorar bastante y tener resultados que no serán los mejores.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el modelo base\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Definir la grilla de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Configurar el GridSearch con validación cruzada de 3 folds\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar mejores parámetros y score\n",
    "print(\"🔍 Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"📉 Mejor RMSE (negativo): {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7fd310",
   "metadata": {},
   "source": [
    "Una vez ejecutado el bloque de código anterior, se obtuvieron los sigueintes hiperparámetros con un RMSE (negativo) de -8920.4557:  \n",
    "\n",
    "max_depth: **None** (los otros parámetros compensan el riesgo de overfitting)  \n",
    "max_features: **log2** (subconjunto reducido de columnas)  \n",
    "min_samples_leaf: **1** (las hohas del arbol tienen una sola muestra, es decir, una alta resolución)  \n",
    "min_samples_split: **2** (las ramas se dividen con solo 2 muestras)  \n",
    "n_estimators: **100** (se usan 100 árboles)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ee9cd",
   "metadata": {},
   "source": [
    "Se procede a ejecutar el entrenamiento con los mejores parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66597796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir X e y\n",
    "X = df_encoded.drop(columns=['price'])\n",
    "y = df_encoded['price']\n",
    "\n",
    "# 2. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Entrenar modelo optimizado\n",
    "modelo_optimo = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "modelo_optimo.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predecir\n",
    "y_pred = modelo_optimo.predict(X_test)\n",
    "\n",
    "# 5. Métricas\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"📊 MAE:  {mae:.2f}\")\n",
    "print(f\"📊 RMSE: {rmse:.2f}\")\n",
    "print(f\"📊 R²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7b99e",
   "metadata": {},
   "source": [
    "#### 6.1.3. Trazar curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ebc79e",
   "metadata": {},
   "source": [
    "Se debe comprender como evoluciona el rendimiento del modelo a medida que se agregan más datos al entrenamiento y luego saber si se necesitan más datos o hay un sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import LearningCurveDisplay\n",
    "\n",
    "# 1. Crear el modelo base\n",
    "estimator = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Definir el método de validación cruzada\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Trazar la curva de aprendizaje usando R²\n",
    "LearningCurveDisplay.from_estimator(\n",
    "    estimator=estimator,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),  # 5 puntos de entrenamiento: 10% a 100%\n",
    ")\n",
    "\n",
    "plt.title(\"Curva de Aprendizaje - Random Forest (R²)\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54566e07",
   "metadata": {},
   "source": [
    "Se observa que el R² de Train es mucho mayor que Test. Esto significa que el modelo está sobreajustado (aprende demasiado bien los datos de entrenamiento y generaliza peor).\n",
    "Se observa que a mayor tamaño de entrenamiento, mejora el R² de Test, es decir, más datos ayudan a generalizar mejor.\n",
    "En general, el modelo tiene buena capacidad predictiva, pero hay espacio para mejorar la generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa5d90",
   "metadata": {},
   "source": [
    "#### 6.1.4. Importancia de las características (Feature Importance) de RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793e77b",
   "metadata": {},
   "source": [
    "En RandomForestRegressor, la importancia de una característica se mide como la reducción total de error (por ejemplo, MSE) atribuible a cada feature, promediada entre todos los árboles del bosque.  \n",
    "El resultado es un valor entre 0 y 1 para cada feature. Cuanto mayor el valor, más importante fue esa columna en las decisiones del modelo. Para obtener esto se debe ejecutar el siguiente bloque de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = modelo_optimo.feature_importances_\n",
    "columnas = X_train.columns\n",
    "\n",
    "# Crear un DataFrame ordenado\n",
    "importancias_df = pd.DataFrame({\n",
    "    'Feature': columnas,\n",
    "    'Importancia': importancia\n",
    "}).sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "# Mostrar las 30 características más importantes ordenadas\n",
    "top_importancias = importancias_df.head(30)\n",
    "\n",
    "for i, row in top_importancias.iterrows():\n",
    "    print(f\"{i+1:2d}. {row['Feature']:40s} --> {row['Importancia']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(top_importancias['Feature'][::-1], top_importancias['Importancia'][::-1], color='skyblue')\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.title(\"Top 30 características más importantes según Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d65cb8",
   "metadata": {},
   "source": [
    "**Conclusiones del análisis de importancia de características:**  \n",
    "\n",
    "**Dominio de pocas variables:** odometer (0.1591), year (0.1382) y vehicle_age (0.1369) concentran una gran parte de la importancia total.  \n",
    "**Desbalance de relevancia:** Desde la posición 4 en adelante, la importancia de las características cae drásticamente.   \n",
    "**Alta dimensionalidad:** Muchas columnas apenas aportan entre 0.005 y 0.01, lo cual indica que son poco útiles para la predicción.  \n",
    "**Redundancias:** Algunas columnas parecen variantes de una misma información. Ej: year y vehicle_age, model_grouped_unknown y model_grouped_other.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccddcc",
   "metadata": {},
   "source": [
    "#### 6.1.5. Mejoras en base al Feature Importance y la curva de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar variables de baja importancia\n",
    "columnas_a_eliminar = importancias_df[importancias_df['Importancia'] < 0.005]['Feature']\n",
    "X_train_filtrado = X_train.drop(columns=columnas_a_eliminar)\n",
    "X_test_filtrado = X_test.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Eliminar columna 'year' si existe\n",
    "for df in [X_train_filtrado, X_test_filtrado]:\n",
    "    if 'year' in df.columns:\n",
    "        df.drop(columns='year', inplace=True)\n",
    "\n",
    "# Combinar 'model_grouped_unknown' y 'model_grouped_other' en 'model_grouped_misc'\n",
    "for df in [X_train_filtrado, X_test_filtrado]:\n",
    "    if 'model_grouped_unknown' in df.columns and 'model_grouped_other' in df.columns:\n",
    "        df['model_grouped_misc'] = df['model_grouped_unknown'] + df['model_grouped_other']\n",
    "        df.drop(columns=['model_grouped_unknown', 'model_grouped_other'], inplace=True)\n",
    "    elif 'model_grouped_unknown' in df.columns:\n",
    "        df.rename(columns={'model_grouped_unknown': 'model_grouped_misc'}, inplace=True)\n",
    "    elif 'model_grouped_other' in df.columns:\n",
    "        df.rename(columns={'model_grouped_other': 'model_grouped_misc'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ddc3e8",
   "metadata": {},
   "source": [
    "Aplicaremos nuevamente RandomForestRegressor pero teniendo en cuenta de evitar el sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8895f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Entrenar modelo con parámetros para reducir sobreajuste\n",
    "# Antes los parámetros eran:\n",
    "#    n_estimators=100,\n",
    "#    max_depth=None,\n",
    "#    max_features='log2',\n",
    "#    min_samples_leaf=1,\n",
    "#    min_samples_split=2,\n",
    "#    random_state=42\n",
    "\n",
    "modelo_regularizado = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "modelo_regularizado.fit(X_train_filtrado, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred = modelo_regularizado.predict(X_train_filtrado)\n",
    "y_test_pred = modelo_regularizado.predict(X_test_filtrado)\n",
    "\n",
    "# Métricas\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"=== Métricas de Entrenamiento ===\")\n",
    "print(f\"MAE:  {mae_train:.2f}\")\n",
    "print(f\"RMSE: {rmse_train:.2f}\")\n",
    "print(f\"R²:   {r2_train:.4f}\")\n",
    "\n",
    "print(\"\\n=== Métricas de Test ===\")\n",
    "print(f\"MAE:  {mae_test:.2f}\")\n",
    "print(f\"RMSE: {rmse_test:.2f}\")\n",
    "print(f\"R²:   {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a2b4a",
   "metadata": {},
   "source": [
    "### 6.2. **MODELADO DE CONJUNTOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cac68e",
   "metadata": {},
   "source": [
    "#### 6.2.1. Obtener un segundo modelo con otro método"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476a8de",
   "metadata": {},
   "source": [
    "Para esto, se hará uso de XGBoost. Primero se debe ejecutar *\"pip install xgboost\"* para instalar XGBoost en tu sistema.  \n",
    "Luego se procede con el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d69d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "modelo_xgb = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09456597",
   "metadata": {},
   "source": [
    "#### 6.2.2. Combinando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cf5cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849814f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = (y_pred_rf + y_pred_xgb) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d9be1c",
   "metadata": {},
   "source": [
    "### 6.3. **PREDICCIÓN FINAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4abac",
   "metadata": {},
   "source": [
    "#### 6.3.1. Predecir y evaluar resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214a0bb",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 7. **CONCLUSIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce688f",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________\n",
    "## 8. **PRÓXIMAS LÍNEAS**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
